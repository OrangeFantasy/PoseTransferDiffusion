model:
  lr: 0.0001

  target: diffusion.models.ddpm.PoseTransferDiffusion
  params:
    timesteps: 1000
    beta_schedule: "linear"
    beta_1: 0.0001
    beta_T: 0.02
    cosine_s: 0.003
    loss_type: "l2"
    v_posterior: 0.0
    parameterization: "eps"
    # ckpt_path: 

    unet_config:
      target: diffusion.modules.diffusionmodules.unet.UNetModel
      params:
        in_ch: 8
        out_ch: 4
        model_ch: 128
        num_res_blocks: 2
        attn_resolutions: [2, 4]
        ch_mult: [1, 2, 4, 4]
        dim_head: 64
        context_dim: 128
        context_ch: 4
    
    first_stage_config:
      target: diffusion.models.autoencoder.AutoencoderKL
      params:
        ckpt_path: E:/_Project\stable-diffusion-webui/models/VAE/vae-ft-mse-840000-ema-pruned.ckpt
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      target:
      params:

# data: 
#   num_workers: 8
#   train_batch_size: 1
#   test_batch_size: 1
  
#   dataset_config:
#     target: data.dataset.deep_fashion.DeepFashionDataset
#     params:
#       root: "E:/_Project/_Dataset/In-shop Clothes Retrieval Benchmark"
#       image_size: [256, 256]

data: 
  target: data.data_interface.DataInterFace
  params: 
    num_workers: 8
    train_batch_size: 1
    test_batch_size: 1
    
    dataset_config:
      target: data.dataset.deep_fashion.DeepFashionDataset
      params:
        root: "E:/_Project/_Dataset/In-shop Clothes Retrieval Benchmark"
        image_size: [256, 256]
